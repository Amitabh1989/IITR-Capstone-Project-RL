{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "190cf570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b157c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.envs.registration import register\n",
    "\n",
    "try:\n",
    "    register(\n",
    "        id='Amitabh-FrozenLakeNotSlippery-v0',\n",
    "        entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "        kwargs={'map_name' : '4x4', 'is_slippery': False},\n",
    "        max_episode_steps= 100,\n",
    "        reward_threshold= 0.78\n",
    "    )\n",
    "except:\n",
    "    print(\"Environment already created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4b7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Amitabh-FrozenLakeNotSlippery-v0\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8ce9b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a7a14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8b597b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a60725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7075a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros([env.observation_space.n, env.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a18acf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8370ab89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa520647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, {'prob': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4b225ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below function is a very raw, novice way to randomly select any action and perform on the environment. It has nothing to do with \n",
    "# machine learning or any such thing. \n",
    "for episode in range(5):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, truncate, info = env.step(action)\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d01d119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets implement it via code to see how machine learns to play this game and how can we teach the machine to do it\n",
    "# Starting with the Q learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34928d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things we need\n",
    "# 1. EPSILON GREEDY METHOD\n",
    "# 2. Function to compute optimal q value\n",
    "# 3. Few necessary variables : EPSILON, discount factor GAMMA, lerning rate ALPHA and other for loop control and Epsilon decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d78cea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS:\n",
    "NUM_EPISODES = 20000\n",
    "ALPHA = 0.01\n",
    "GAMMA = 0.99\n",
    "EPSILON = 1.0\n",
    "MIN_EPSILON = 0.0\n",
    "MAX_EPSILON = 1.0\n",
    "EPSILON_DECAY = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06836303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_action(q_table, state):\n",
    "    random_val = np.random.random()\n",
    "    if random_val > EPSILON:\n",
    "        action = np.argmax(q_table[state, :]) # argmax gets me the action\n",
    "    \n",
    "    else:\n",
    "        action = env.action_space.sample()\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fdd70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_next_q_val(old_q_val, reward, next_optimal_q_val):\n",
    "    return (old_q_val + ALPHA * (reward + (GAMMA * next_optimal_q_val) - old_q_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14b34ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_epsilon(epsilon, episode):\n",
    "    return (MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON)*np.exp(-EPSILON_DECAY*episode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc9a8671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPISODE :  0   Reward :  0.0\n",
      "EPISODE :  1000   Reward :  122.0\n",
      "EPISODE :  2000   Reward :  481.0\n",
      "EPISODE :  3000   Reward :  923.0\n",
      "EPISODE :  4000   Reward :  1406.0\n",
      "EPISODE :  5000   Reward :  1901.0\n",
      "EPISODE :  6000   Reward :  2398.0\n",
      "EPISODE :  7000   Reward :  2898.0\n",
      "EPISODE :  8000   Reward :  3398.0\n",
      "EPISODE :  9000   Reward :  3898.0\n",
      "EPISODE :  10000   Reward :  4398.0\n",
      "EPISODE :  11000   Reward :  4898.0\n",
      "EPISODE :  12000   Reward :  5398.0\n",
      "EPISODE :  13000   Reward :  5898.0\n",
      "EPISODE :  14000   Reward :  6398.0\n",
      "EPISODE :  15000   Reward :  6898.0\n",
      "EPISODE :  16000   Reward :  7398.0\n",
      "EPISODE :  17000   Reward :  7898.0\n",
      "EPISODE :  18000   Reward :  8398.0\n",
      "EPISODE :  19000   Reward :  8898.0\n",
      "EPISODE :  20000   Reward :  9398.0\n",
      "EPISODE :  21000   Reward :  9898.0\n",
      "EPISODE :  22000   Reward :  10398.0\n",
      "EPISODE :  23000   Reward :  10898.0\n",
      "EPISODE :  24000   Reward :  11398.0\n",
      "EPISODE :  25000   Reward :  11898.0\n",
      "EPISODE :  26000   Reward :  12398.0\n",
      "EPISODE :  27000   Reward :  12898.0\n",
      "EPISODE :  28000   Reward :  13398.0\n",
      "EPISODE :  29000   Reward :  13898.0\n",
      "EPISODE :  30000   Reward :  14398.0\n",
      "EPISODE :  31000   Reward :  14898.0\n",
      "EPISODE :  32000   Reward :  15398.0\n",
      "EPISODE :  33000   Reward :  15898.0\n",
      "EPISODE :  34000   Reward :  16398.0\n",
      "EPISODE :  35000   Reward :  16898.0\n",
      "EPISODE :  36000   Reward :  17398.0\n",
      "EPISODE :  37000   Reward :  17898.0\n",
      "EPISODE :  38000   Reward :  18398.0\n",
      "EPISODE :  39000   Reward :  18898.0\n"
     ]
    }
   ],
   "source": [
    "log_interval = 1000\n",
    "rewards = []\n",
    "for episode in range(NUM_EPISODES):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    state = state[0] if isinstance(state, tuple) else state\n",
    "    total_rewards = 0\n",
    "   \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        \n",
    "        # Choose an action and perform\n",
    "        action = epsilon_greedy_action(q_table, state)\n",
    "        next_state, reward, done, truncate, info = env.step(action)\n",
    "        \n",
    "        # Get old q val\n",
    "        old_q_val = q_table[state, action]\n",
    "        \n",
    "        # Get next optimal q val\n",
    "        next_optimal_q_val = np.max(q_table[next_state, :]) # whole row as we dont know what action is to be take.\n",
    "        \n",
    "        # Compute next q val\n",
    "        new_q_val = compute_next_q_val(old_q_val, reward, next_optimal_q_val)\n",
    "        \n",
    "        # Update the q table\n",
    "        q_table[state, action] = new_q_val\n",
    "        \n",
    "        \n",
    "        # Update current state\n",
    "        state = next_state\n",
    "        \n",
    "        # accumulate total reward\n",
    "        total_rewards += reward\n",
    "\n",
    "    # Decay EPSILON\n",
    "    episode += episode\n",
    "    EPSILON = reduce_epsilon(EPSILON, episode)\n",
    "    rewards.append(total_rewards)\n",
    "    \n",
    "    if episode % log_interval == 0:\n",
    "        print(\"EPISODE : \", episode, \"  Reward : \", np.sum(rewards))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d769401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.18794713e-01, 1.99853974e-03, 9.50990050e-01, 1.53902424e-01],\n",
       "       [1.65803992e-01, 0.00000000e+00, 9.60596010e-01, 1.60042995e-01],\n",
       "       [1.96575186e-01, 9.70299000e-01, 4.28346065e-02, 2.34994976e-01],\n",
       "       [2.49112409e-01, 0.00000000e+00, 1.57019061e-03, 9.48804024e-04],\n",
       "       [6.42103985e-05, 1.65634695e-02, 0.00000000e+00, 9.13252951e-05],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 9.80100000e-01, 0.00000000e+00, 2.10071280e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.32544791e-03, 0.00000000e+00, 1.08802639e-01, 2.73715046e-05],\n",
       "       [2.78151587e-03, 9.36215375e-03, 4.80344161e-01, 0.00000000e+00],\n",
       "       [8.77445892e-02, 9.90000000e-01, 0.00000000e+00, 3.27681439e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 4.57092082e-03, 3.89843800e-01, 1.46332974e-03],\n",
       "       [9.00700251e-02, 3.84692312e-01, 1.00000000e+00, 2.84288297e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10f29abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_human = gym.make(\"Amitabh-FrozenLakeNotSlippery-v0\", render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b816b95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n",
      "Woohoo, you won!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "i = 1\n",
    "for episode in range(200):\n",
    "    done = False\n",
    "    state = env_human.reset()\n",
    "    state = state[0] if isinstance(state, tuple) else state\n",
    "    while not done:\n",
    "        env_human.render()\n",
    "        action = np.argmax(q_table[state, :])\n",
    "        state, reward, done, truncate, info = env_human.step(action)\n",
    "        if i == 1:\n",
    "            time.sleep(10)\n",
    "            i += 1\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "        if done:\n",
    "            print(\"Woohoo, you won!\")\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61afc4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff1c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cca6286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80654e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c515752b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b840a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86894a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
